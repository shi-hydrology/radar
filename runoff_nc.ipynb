{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffdf24d3-9855-4019-bc3c-8124d4d46c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "from osgeo import gdal, osr, gdalconst, ogr\n",
    "import pandas as pd\n",
    "\n",
    "gdal.UseExceptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f49d5b-5010-4795-be93-dd947c0f6df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
      "    Conventions: CF-1.6\n",
      "    Title: E-RUN version 1.1\n",
      "    Institution: ETH Zurich\n",
      "    dimensions(sizes): lon(232), lat(101), time(781)\n",
      "    variables(dimensions): float64 lon(lon), float64 lat(lat), float64 time(time), float32 runoff(time, lat, lon)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "in_path = \"/home/antonv/PycharmProjects/lena/nc/e-run_v1.1.nc\"\n",
    "\n",
    "a = nc.Dataset(in_path)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc66f33f-bb32-48c6-a1a1-fc103aba71cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 runoff(time, lat, lon)\n",
      "    long_name: Total runoff\n",
      "    units: mm/day\n",
      "    _FillValue: -9999.0\n",
      "    missing_value: -9999.0\n",
      "    time_statistic: accumulation\n",
      "unlimited dimensions: time\n",
      "current shape = (781, 101, 232)\n",
      "filling on\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for var in a.variables.values():\n",
    "    print(var)\n",
    "\"\"\"\n",
    "print(a['runoff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f1800e-52e6-4b41-9f1c-5accd2f4b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 lon(lon)\n",
      "    standard_name: longitude\n",
      "    long_name: longitude\n",
      "    units: degrees_east\n",
      "    axis: X\n",
      "unlimited dimensions: \n",
      "current shape = (232,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "[-40.25 -39.75 -39.25 -38.75 -38.25 -37.75 -37.25 -36.75 -36.25 -35.75\n",
      " -35.25 -34.75 -34.25 -33.75 -33.25 -32.75 -32.25 -31.75 -31.25 -30.75\n",
      " -30.25 -29.75 -29.25 -28.75 -28.25 -27.75 -27.25 -26.75 -26.25 -25.75\n",
      " -25.25 -24.75 -24.25 -23.75 -23.25 -22.75 -22.25 -21.75 -21.25 -20.75\n",
      " -20.25 -19.75 -19.25 -18.75 -18.25 -17.75 -17.25 -16.75 -16.25 -15.75\n",
      " -15.25 -14.75 -14.25 -13.75 -13.25 -12.75 -12.25 -11.75 -11.25 -10.75\n",
      " -10.25  -9.75  -9.25  -8.75  -8.25  -7.75  -7.25  -6.75  -6.25  -5.75\n",
      "  -5.25  -4.75  -4.25  -3.75  -3.25  -2.75  -2.25  -1.75  -1.25  -0.75\n",
      "  -0.25   0.25   0.75   1.25   1.75   2.25   2.75   3.25   3.75   4.25\n",
      "   4.75   5.25   5.75   6.25   6.75   7.25   7.75   8.25   8.75   9.25\n",
      "   9.75  10.25  10.75  11.25  11.75  12.25  12.75  13.25  13.75  14.25\n",
      "  14.75  15.25  15.75  16.25  16.75  17.25  17.75  18.25  18.75  19.25\n",
      "  19.75  20.25  20.75  21.25  21.75  22.25  22.75  23.25  23.75  24.25\n",
      "  24.75  25.25  25.75  26.25  26.75  27.25  27.75  28.25  28.75  29.25\n",
      "  29.75  30.25  30.75  31.25  31.75  32.25  32.75  33.25  33.75  34.25\n",
      "  34.75  35.25  35.75  36.25  36.75  37.25  37.75  38.25  38.75  39.25\n",
      "  39.75  40.25  40.75  41.25  41.75  42.25  42.75  43.25  43.75  44.25\n",
      "  44.75  45.25  45.75  46.25  46.75  47.25  47.75  48.25  48.75  49.25\n",
      "  49.75  50.25  50.75  51.25  51.75  52.25  52.75  53.25  53.75  54.25\n",
      "  54.75  55.25  55.75  56.25  56.75  57.25  57.75  58.25  58.75  59.25\n",
      "  59.75  60.25  60.75  61.25  61.75  62.25  62.75  63.25  63.75  64.25\n",
      "  64.75  65.25  65.75  66.25  66.75  67.25  67.75  68.25  68.75  69.25\n",
      "  69.75  70.25  70.75  71.25  71.75  72.25  72.75  73.25  73.75  74.25\n",
      "  74.75  75.25]\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 lat(lat)\n",
      "    standard_name: latitude\n",
      "    long_name: latitude\n",
      "    units: degrees_north\n",
      "    axis: Y\n",
      "unlimited dimensions: \n",
      "current shape = (101,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "[25.25 25.75 26.25 26.75 27.25 27.75 28.25 28.75 29.25 29.75 30.25 30.75\n",
      " 31.25 31.75 32.25 32.75 33.25 33.75 34.25 34.75 35.25 35.75 36.25 36.75\n",
      " 37.25 37.75 38.25 38.75 39.25 39.75 40.25 40.75 41.25 41.75 42.25 42.75\n",
      " 43.25 43.75 44.25 44.75 45.25 45.75 46.25 46.75 47.25 47.75 48.25 48.75\n",
      " 49.25 49.75 50.25 50.75 51.25 51.75 52.25 52.75 53.25 53.75 54.25 54.75\n",
      " 55.25 55.75 56.25 56.75 57.25 57.75 58.25 58.75 59.25 59.75 60.25 60.75\n",
      " 61.25 61.75 62.25 62.75 63.25 63.75 64.25 64.75 65.25 65.75 66.25 66.75\n",
      " 67.25 67.75 68.25 68.75 69.25 69.75 70.25 70.75 71.25 71.75 72.25 72.75\n",
      " 73.25 73.75 74.25 74.75 75.25]\n"
     ]
    }
   ],
   "source": [
    "print(a['lon'])\n",
    "print(a['lon'][:])\n",
    "print(a['lat'])\n",
    "print(a['lat'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e98b627e-9704-429c-89e0-f40611bf20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata = -9999\n",
    "\n",
    "def create_mask(raster_ds, vector_path, out_mask_path, disk_output=False):\n",
    "    shp = vector_path\n",
    "    data = raster_ds\n",
    "    geo_transform = data.GetGeoTransform()\n",
    "    proj = data.GetProjection()\n",
    "    # source_layer = data.GetLayer()\n",
    "    x_min = geo_transform[0]\n",
    "    y_max = geo_transform[3]\n",
    "    x_max = x_min + geo_transform[1] * data.RasterXSize\n",
    "    y_min = y_max + geo_transform[5] * data.RasterYSize\n",
    "    x_res = data.RasterXSize\n",
    "    y_res = data.RasterYSize\n",
    "    mb_v = ogr.Open(shp)\n",
    "    mb_l = mb_v.GetLayer()\n",
    "    pixel_width = geo_transform[1]\n",
    "    \n",
    "    drv = \"GTiff\" if disk_output == True else \"MEM\"\n",
    "    out_mask_path = out_mask_path if disk_output == True else \"\"\n",
    "    target_ds = gdal.GetDriverByName(drv).Create(out_mask_path, x_res, y_res, 1, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform((x_min, pixel_width, 0, y_min, 0, pixel_width))\n",
    "    target_ds.SetProjection(proj)\n",
    "    band = target_ds.GetRasterBand(1)\n",
    "    band.SetNoDataValue(nodata)\n",
    "    band.FlushCache()\n",
    "    \n",
    "    gdal.RasterizeLayer(target_ds, [1], mb_l, options=[\"ATTRIBUTE=Id\"])\n",
    "    mask_arr = target_ds.GetRasterBand(1).ReadAsArray().copy()\n",
    "\n",
    "    target_ds = None\n",
    "    mask_arr = np.rot90(mask_arr,2)  # WHY??!\n",
    "    mask_arr = np.flip(mask_arr,1)\n",
    "    return mask_arr\n",
    "\n",
    "def crop_variable_to_watershed(arr, ws_path, out_path=None, v=False):\n",
    "    # 1) создаём массив для привязки изображения в формате GDAL GeoTransform:\n",
    "    \"\"\"\n",
    "    GDAL GeoTransform:\n",
    "    GT(0) x-coordinate of the upper-left corner of the upper-left pixel.\n",
    "    GT(1) w-e pixel resolution / pixel width.\n",
    "    GT(2) row rotation (typically zero).\n",
    "    GT(3) y-coordinate of the upper-left corner of the upper-left pixel.\n",
    "    GT(4) column rotation (typically zero).\n",
    "    GT(5) n-s pixel resolution / pixel height (negative value for a north-up image).\n",
    "    \"\"\"\n",
    "    s = arr.shape\n",
    "    # print(arr.shape)\n",
    "    # res = 0.5 # grid resolution in degrees\n",
    "    lon_res = a['lon'][1] - a['lon'][0]\n",
    "    lat_res = a['lat'][1] - a['lat'][0]\n",
    "\n",
    "    xul = a['lon'][0]\n",
    "    yul = a['lat'][-1]\n",
    "    gt = [xul, lon_res, 0, yul, 0, -lat_res]  # GeoTransform готов\n",
    "\n",
    "    # 2) вызываем драйвер GTiff и просим его создать нам новый файл нужного размера с одним растровым каналом:\n",
    "    if out_path is None:\n",
    "        out_path = \"\"\n",
    "        drv = \"MEM\"\n",
    "    else:\n",
    "        drv = \"GTiff\"\n",
    "\n",
    "    driver = gdal.GetDriverByName(drv)\n",
    "    rows, cols = s\n",
    "    no_bands = 1\n",
    "    # ds = driver.Create(out_path, cols, rows, no_bands, gdal.GDT_Byte)\n",
    "    ds = driver.Create(out_path, cols, rows, no_bands, gdal.GDT_Float32)\n",
    "\n",
    "    # 3) записываем в файл массив измерений, значение \"нет данных\" и геотрансформ:\n",
    "    ds.GetRasterBand(1).WriteArray(arr)\n",
    "    ds.GetRasterBand(1).SetNoDataValue(nodata)\n",
    "    ds.SetGeoTransform(gt)\n",
    "\n",
    "    # 4) прикрепляем к файлу информацию о системе координат:\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(4326)  # WGS84\n",
    "    ds.SetProjection(srs.ExportToWkt())\n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "    # 5) обрезаем по водосбору:\n",
    "    out_path = \"runoff_%s_crop.tif\" % date_str\n",
    "    # crop_ds = gdal.Warp(out_path, ds, format=\"GTiff\", cutlineDSName=ws_path, cropToCutline=True)  # does not work without cropToCutline=True\n",
    "    # print(crop_ds)\n",
    "    # НЕ РАБОТАЕТ ДЛЯ СЛИШКОМ МАЛЕНЬКИХ ВОДОСБОРОВ (КАК У ЛЕНЫ)\n",
    "\n",
    "    ##################################################################################################\n",
    "    # 5a) альтернативный путь для мелких водосборов: растеризуем водосбор и используем получившийся растр как маску, внутри которой считаем среднее значение:\n",
    "    out_path = \"runoff_mask.tif\"  # will be ignored if disk_output=False\n",
    "    mask_arr = create_mask(ds, ws_path, out_path, disk_output=False)\n",
    "    # plt.imshow(mask_arr)\n",
    "\n",
    "    masked_arr = np.where(mask_arr > 0, arr, nodata)\n",
    "    # plt.imshow(masked_arr)\n",
    "    # plt.colorbar()\n",
    "\n",
    "    ds.GetRasterBand(1).WriteArray(masked_arr)\n",
    "\n",
    "    m = masked_arr[masked_arr != nodata].mean()\n",
    "    if v:\n",
    "        print(\"Mean value is %.1f mm per day\" % m)\n",
    "\n",
    "    #############################################################################################\n",
    "    # 6) все операции с исходной картинкой выполнялись до этого момента в оперативной памяти\n",
    "    # запись на диск будет произведена только после выполнения следующих команд:\n",
    "    ds.FlushCache()\n",
    "    ds = None\n",
    "    \n",
    "    return m\n",
    "\n",
    "def fmt_date(nc_time):\n",
    "    # print(nc_time, \"days\")\n",
    "    delta = timedelta(days=float(nc_time))\n",
    "    return datetime.strptime(\"1950-01-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\") + delta\n",
    "\n",
    "\n",
    "def show_runoff(arr, date_str):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(date_str)\n",
    "    im = ax.imshow(arr)\n",
    "    fig.colorbar(im, label=\"mm/day\", orientation=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38fa3a7f-978e-423e-90b2-d08400c88c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1950-12-16 00:00:00 [0/781]\n",
      "Processing 1959-04-15 12:00:00 [100/781]\n",
      "Processing 1967-08-16 00:00:00 [200/781]\n",
      "Processing 1975-12-16 00:00:00 [300/781]\n",
      "Processing 1984-04-15 12:00:00 [400/781]\n",
      "Processing 1992-08-16 00:00:00 [500/781]\n",
      "Processing 2000-12-16 00:00:00 [600/781]\n",
      "Processing 2009-04-15 12:00:00 [700/781]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>mean_runoff_mm_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950-12-16 00:00:00</td>\n",
       "      <td>0.635893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951-01-16 00:00:00</td>\n",
       "      <td>0.236675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951-02-14 12:00:00</td>\n",
       "      <td>0.140853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951-03-16 00:00:00</td>\n",
       "      <td>0.179860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1951-04-15 12:00:00</td>\n",
       "      <td>2.143269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_time  mean_runoff_mm_day\n",
       "0 1950-12-16 00:00:00            0.635893\n",
       "1 1951-01-16 00:00:00            0.236675\n",
       "2 1951-02-14 12:00:00            0.140853\n",
       "3 1951-03-16 00:00:00            0.179860\n",
       "4 1951-04-15 12:00:00            2.143269"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>mean_runoff_mm_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>2015-08-16 00:00:00</td>\n",
       "      <td>0.217626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>2015-09-15 12:00:00</td>\n",
       "      <td>0.214607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>2015-10-16 00:00:00</td>\n",
       "      <td>0.251058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>2015-11-15 12:00:00</td>\n",
       "      <td>0.404580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>2015-12-16 00:00:00</td>\n",
       "      <td>0.809839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date_time  mean_runoff_mm_day\n",
       "776 2015-08-16 00:00:00            0.217626\n",
       "777 2015-09-15 12:00:00            0.214607\n",
       "778 2015-10-16 00:00:00            0.251058\n",
       "779 2015-11-15 12:00:00            0.404580\n",
       "780 2015-12-16 00:00:00            0.809839"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ws_path = \"/home/antonv/PycharmProjects/lena/nc/ws/fix_Lychkovo_g.geojson\"\n",
    "# ws_path = \"/home/antonv/PycharmProjects/lena/nc/ws/fix_text.geojson\"\n",
    "\n",
    "date_list = []\n",
    "mean_list = []\n",
    "\n",
    "time_len = len(a[\"time\"])\n",
    "\n",
    "for i in range(0, time_len):\n",
    "    # print(a['time'][i])  # days since 1950-1-1 00:00:00\n",
    "    date_str = fmt_date(a['time'][i])\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"Processing\", date_str, \"[%s/%s]\" % (i, time_len))\n",
    "        \n",
    "    date_list.append(date_str)\n",
    "\n",
    "    arr = a['runoff'][i, :, :]\n",
    "\n",
    "    arr = np.rot90(arr, 2)  # WHY??!\n",
    "    arr = np.flip(arr, 1)\n",
    "\n",
    "    # show_runoff(arr, date_str)\n",
    "\n",
    "    out_path = \"runoff_%s.tif\" % date_str\n",
    "    # crop_variable_to_watershed(arr, ws_path, out_path=out_path)\n",
    "    mean = crop_variable_to_watershed(arr, ws_path, out_path=None)\n",
    "    mean_list.append(mean)\n",
    "\n",
    "df = pd.DataFrame({\"date_time\": date_list, \"mean_runoff_mm_day\": mean_list})\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "\n",
    "df.to_csv(\"reanalysis_runoff_test.csv\", float_format='%.2f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8136c0-353d-44fb-adfb-18a0f6e57f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
